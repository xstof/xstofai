{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25617f9",
   "metadata": {},
   "source": [
    "# NanoGPT - Math Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57bd687",
   "metadata": {},
   "source": [
    "## Building manual intuition: averaging prior token features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.set_printoptions(precision=1, sci_mode=False, profile='short')\n",
    "generator = torch.manual_seed(42)\n",
    "\n",
    "batch_size = 4\n",
    "context_length = 6\n",
    "vocab_size = 8 # 8 characters or language tokens possible\n",
    "\n",
    "B,T,C = (batch_size, context_length, vocab_size)\n",
    "B,T,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.48,  1.35, -0.16, -0.42,  0.94, -0.18,  1.06,  0.21],\n",
       "         [ 1.31,  0.46,  0.26, -0.76, -2.05, -1.53,  0.40,  0.63],\n",
       "         [-0.15, -2.32,  1.30,  0.49,  1.13, -0.36,  0.36,  2.00],\n",
       "         [ 1.04,  1.69,  0.02, -0.83, -1.08, -0.78,  0.51,  0.08],\n",
       "         [ 0.40,  1.99, -0.46, -0.06, -1.37,  0.33, -0.98,  0.30],\n",
       "         [ 0.19,  0.41, -1.58,  2.25,  1.00,  1.36,  0.63,  0.41]],\n",
       "\n",
       "        [[-0.35,  1.46,  0.17,  1.05,  0.01, -0.08,  0.64,  0.57],\n",
       "         [ 0.51,  0.22, -0.91,  1.48, -0.91, -0.53, -0.81,  0.52],\n",
       "         [-0.13,  0.78,  0.56,  1.86,  1.04, -0.86,  0.84, -0.32],\n",
       "         [-1.98,  0.02, -1.41, -1.88, -0.18,  0.79,  0.52, -0.27],\n",
       "         [ 1.71,  0.06,  0.86, -0.59, -1.03, -0.22,  0.80,  0.91],\n",
       "         [ 0.27, -0.04, -0.48,  0.32,  0.39,  0.73,  0.25,  0.08]],\n",
       "\n",
       "        [[-0.71, -0.05,  0.52,  0.97, -0.28, -0.61, -0.56, -0.97],\n",
       "         [ 1.34,  0.71,  0.35, -0.54,  0.86, -0.67,  1.07, -0.25],\n",
       "         [-2.31, -1.29,  0.21, -1.24,  1.86,  0.06,  0.77,  2.56],\n",
       "         [ 1.20, -0.98,  0.30,  0.93, -1.97, -1.41,  1.74,  1.84],\n",
       "         [-0.00,  0.08, -0.46, -0.06, -0.22, -1.25, -0.49, -0.34],\n",
       "         [-0.59,  0.08,  0.19, -0.97,  1.89,  0.44,  0.14,  0.31]],\n",
       "\n",
       "        [[-0.49,  0.05,  0.33,  0.13,  2.85, -0.74,  0.20, -1.34],\n",
       "         [-0.57, -0.33, -0.31, -0.72,  0.08, -0.21, -0.57,  0.40],\n",
       "         [-0.55,  1.99,  0.85, -0.70,  0.31,  0.29,  0.41, -1.26],\n",
       "         [-0.39,  1.89,  0.18, -0.04, -0.09, -1.18,  1.55,  0.54],\n",
       "         [-0.20,  0.69, -1.34,  1.65,  1.98, -0.10,  0.49, -0.44],\n",
       "         [-0.49, -0.36, -0.06, -0.48,  0.99,  0.27, -1.83,  0.36]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x is our training data\n",
    "x = torch.randn(batch_size,context_length, vocab_size)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4329aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0, -0.3, -1.3, -0.6,  0.5,  0.5,  1.1,  0.1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the 2nd item in our batch (index 1), the features of token 5 (index 4) are:\n",
    "x[1,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deced6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9, -0.7,  0.1,  0.5, -0.5,  1.2, -0.8, -0.7],\n",
       "        [-1.4,  0.0, -0.1,  0.7, -0.1,  1.8, -1.2,  1.4],\n",
       "        [ 1.4,  0.9,  2.2,  0.5,  0.3, -0.2, -1.1,  1.3],\n",
       "        [-0.2,  0.5,  0.1,  0.4,  0.6, -0.6, -2.2, -0.8]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if instead we want all the features of all the tokens before token 5 (index 4):\n",
    "x[1, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9, -0.7,  0.1,  0.5, -0.5,  1.2, -0.8, -0.7],\n",
       "        [-1.4,  0.0, -0.1,  0.7, -0.1,  1.8, -1.2,  1.4],\n",
       "        [ 1.4,  0.9,  2.2,  0.5,  0.3, -0.2, -1.1,  1.3],\n",
       "        [-0.2,  0.5,  0.1,  0.4,  0.6, -0.6, -2.2, -0.8],\n",
       "        [ 0.0, -0.3, -1.3, -0.6,  0.5,  0.5,  1.1,  0.1]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and if we want to include the features for token 5 itself:\n",
    "x[1,:4+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2,  0.1,  0.2,  0.3,  0.2,  0.5, -0.8,  0.2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to calculate the mean:\n",
    "torch.mean(x[1, :4+1],0) # 0 here means: take means across the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9548d9",
   "metadata": {},
   "source": [
    "Note how the mean of `-0.9, 1.3, -0.7, -1.6, -1.4` is `-0.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77997ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6599999999999999"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.9+1.3-0.7-1.6-1.4)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b219ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bag_of_words = torch.zeros((B,T,C))\n",
    "x_bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd366e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9,  1.5,  0.9, -2.1,  0.7, -1.2, -0.0, -1.6],\n",
       "         [ 0.6,  1.6,  0.3, -1.8, -0.0, -0.9, -0.4, -0.4],\n",
       "         [ 0.9,  1.0,  0.0, -1.0, -0.3, -0.2, -0.0,  0.3],\n",
       "         [ 1.0,  1.1,  0.2, -0.4, -0.3, -0.2, -0.1,  0.4],\n",
       "         [ 0.5,  0.7,  0.1, -0.0, -0.1, -0.2,  0.0,  0.2],\n",
       "         [ 0.2,  0.7, -0.1, -0.1, -0.3,  0.2, -0.2,  0.1]],\n",
       "\n",
       "        [[-0.9, -0.7,  0.1,  0.5, -0.5,  1.2, -0.8, -0.7],\n",
       "         [-1.2, -0.3,  0.0,  0.6, -0.3,  1.5, -1.0,  0.3],\n",
       "         [-0.3,  0.1,  0.7,  0.6, -0.1,  0.9, -1.0,  0.6],\n",
       "         [-0.3,  0.2,  0.6,  0.5,  0.1,  0.5, -1.3,  0.3],\n",
       "         [-0.2,  0.1,  0.2,  0.3,  0.2,  0.5, -0.8,  0.2],\n",
       "         [-0.0, -0.0, -0.0,  0.4, -0.1,  0.3, -0.5,  0.3]],\n",
       "\n",
       "        [[-2.5,  0.5,  0.8,  0.0,  0.6,  0.6,  1.1, -0.5],\n",
       "         [-1.3,  0.6,  0.6,  0.1,  0.5,  0.9,  0.5, -0.4],\n",
       "         [-1.4,  0.4,  0.2,  0.2,  0.5,  0.6,  0.2, -0.1],\n",
       "         [-1.0,  0.3,  0.2,  0.4,  0.7,  0.6,  0.3,  0.0],\n",
       "         [-0.4,  0.5, -0.1,  0.1,  0.5,  0.8,  0.4,  0.2],\n",
       "         [-0.2,  0.4, -0.4,  0.2,  0.4,  0.8,  0.2,  0.2]],\n",
       "\n",
       "        [[-1.0,  1.0,  1.6,  1.5,  0.3, -0.2, -0.7,  0.1],\n",
       "         [-0.3,  1.0,  0.6,  1.5, -1.1, -0.3, -1.0,  0.5],\n",
       "         [-0.8,  0.7,  0.4,  0.9, -0.6, -0.5, -0.6, -0.1],\n",
       "         [-1.0,  0.9,  0.6,  0.7, -0.9, -0.2, -0.2,  0.5],\n",
       "         [-0.8,  0.7,  0.3,  0.5, -0.9, -0.4, -0.4,  0.3],\n",
       "         [-0.8,  0.4, -0.0,  0.4, -0.6, -0.5, -0.2,  0.3]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in range(0,batch_size):\n",
    "    for t in range(0,context_length):\n",
    "        xprev_and_self = x[b,:t+1] # (t+1,vocab_size)\n",
    "        x_bag_of_words[b,t] = torch.mean(xprev_and_self, 0) # (1, vocab_size)\n",
    "x_bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d406c",
   "metadata": {},
   "source": [
    "Note how we calculated before that for:\n",
    "\n",
    "- batch item 2 (index 1)\n",
    "- token 5 (index 4)\n",
    "\n",
    "The bag of words was: `[-0.7,  0.1, -0.6, -0.1, -0.1,  0.1, -0.0,  0.5]`\n",
    "\n",
    "Each of these represent the mean of token 5 and all tokens that came before it, for each channel/features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7dfdf",
   "metadata": {},
   "source": [
    "## Making this efficient\n",
    "\n",
    "What we just did was incredibly inefficient and can be optimized through matrix multiplication.  Let's start by creating some test matrices to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc129b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0., 2.],\n",
       "         [2., 1.],\n",
       "         [1., 3.]]),\n",
       " tensor([[3., 6.],\n",
       "         [3., 6.],\n",
       "         [3., 6.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,3)\n",
    "b = torch.randint(0,4,(3,2)).float() # need to convert to float for matrix multiplication\n",
    "c = a @ b # matrix multiplication\n",
    "\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb5a83",
   "metadata": {},
   "source": [
    "Note how in the first row of matrix c, the `7 8` is the sum of columns `2 3 2` and `2 3 3` because of how matrix multiplying works.  The other rows are exactly the same values (`7 8`) because matrix a has `1` in every row.\n",
    "\n",
    "Let's introduce the `torch.tril()` function now, which gives us back the lower triangle of a matrix, zero-ing out the upper part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6b27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3054862",
   "metadata": {},
   "source": [
    "Let's multiply this by our matrix b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f2709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0., 2.],\n",
       "         [2., 1.],\n",
       "         [1., 3.]]),\n",
       " tensor([[0., 2.],\n",
       "         [2., 3.],\n",
       "         [3., 6.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a @ b\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8319c",
   "metadata": {},
   "source": [
    "The first row of a is multiplied by both the columns of b to get to the first row of b:\n",
    "`(1*2 + 0*3 + 0*2)=2   (1*2 + 0*3 + 0*3)=2` </br>\n",
    "The second row of a is multiplied by both the columns of b to get to the second row of b:\n",
    "`(1*2 + 1*3 + 0*2)=5   (1*2 + 1*3 + 0*3)=5` </br>\n",
    "The third row of a is multiplied by both the columns of b to get to the third row of b:\n",
    "`(1*2 + 1*3 + 1*2)=7   (1*2 + 1*3 + 1*3)=8`\n",
    "\n",
    "Note how:\n",
    "\n",
    "- the first row in the resulting matrix c has the original values of row 1 of b, \n",
    "- the second row has the sum of the values of row 1 and 2 of b and \n",
    "- the third row has the sum of the values of row 1, 2 and 3 of b\n",
    "\n",
    "We don't want to sum however.  We want to try and get to a mean of a value and all values that came before it.  To get the mean, we need to divide the sum by the number of items.  For that reason, we won't use all `1`s to multiply with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f84b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[1.],\n",
       "         [2.],\n",
       "         [3.]]),\n",
       " tensor([[1.0, 0.0, 0.0],\n",
       "         [0.5, 0.5, 0.0],\n",
       "         [0.3, 0.3, 0.3]]),\n",
       " tensor([[0., 2.],\n",
       "         [2., 1.],\n",
       "         [1., 3.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.ones(3,3)\n",
    "a2 = torch.tril(a1)\n",
    "a2_sum = torch.sum(a2, 1, keepdim=True) # keepdim is required given that we need the broadcasting to work\n",
    "a3 = a2 / a2_sum\n",
    "a1, a2, a2_sum, a3, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad009b",
   "metadata": {},
   "source": [
    "If we now want the averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74035e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0, 2.0],\n",
       "        [1.0, 1.5],\n",
       "        [1.0, 2.0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a3 @ b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd237b6e",
   "metadata": {},
   "source": [
    "(see [Let's build GPT: from scratch, in code, spelled out.](https://youtu.be/kCc8FmEb1nY?t=3082) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c05d95",
   "metadata": {},
   "source": [
    "## Applying the matrix technique on our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a199c",
   "metadata": {},
   "source": [
    "Our training data `x` looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1aba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.48,  1.35, -0.16, -0.42,  0.94, -0.18,  1.06,  0.21],\n",
       "         [ 1.31,  0.46,  0.26, -0.76, -2.05, -1.53,  0.40,  0.63],\n",
       "         [-0.15, -2.32,  1.30,  0.49,  1.13, -0.36,  0.36,  2.00],\n",
       "         [ 1.04,  1.69,  0.02, -0.83, -1.08, -0.78,  0.51,  0.08],\n",
       "         [ 0.40,  1.99, -0.46, -0.06, -1.37,  0.33, -0.98,  0.30],\n",
       "         [ 0.19,  0.41, -1.58,  2.25,  1.00,  1.36,  0.63,  0.41]],\n",
       "\n",
       "        [[-0.35,  1.46,  0.17,  1.05,  0.01, -0.08,  0.64,  0.57],\n",
       "         [ 0.51,  0.22, -0.91,  1.48, -0.91, -0.53, -0.81,  0.52],\n",
       "         [-0.13,  0.78,  0.56,  1.86,  1.04, -0.86,  0.84, -0.32],\n",
       "         [-1.98,  0.02, -1.41, -1.88, -0.18,  0.79,  0.52, -0.27],\n",
       "         [ 1.71,  0.06,  0.86, -0.59, -1.03, -0.22,  0.80,  0.91],\n",
       "         [ 0.27, -0.04, -0.48,  0.32,  0.39,  0.73,  0.25,  0.08]],\n",
       "\n",
       "        [[-0.71, -0.05,  0.52,  0.97, -0.28, -0.61, -0.56, -0.97],\n",
       "         [ 1.34,  0.71,  0.35, -0.54,  0.86, -0.67,  1.07, -0.25],\n",
       "         [-2.31, -1.29,  0.21, -1.24,  1.86,  0.06,  0.77,  2.56],\n",
       "         [ 1.20, -0.98,  0.30,  0.93, -1.97, -1.41,  1.74,  1.84],\n",
       "         [-0.00,  0.08, -0.46, -0.06, -0.22, -1.25, -0.49, -0.34],\n",
       "         [-0.59,  0.08,  0.19, -0.97,  1.89,  0.44,  0.14,  0.31]],\n",
       "\n",
       "        [[-0.49,  0.05,  0.33,  0.13,  2.85, -0.74,  0.20, -1.34],\n",
       "         [-0.57, -0.33, -0.31, -0.72,  0.08, -0.21, -0.57,  0.40],\n",
       "         [-0.55,  1.99,  0.85, -0.70,  0.31,  0.29,  0.41, -1.26],\n",
       "         [-0.39,  1.89,  0.18, -0.04, -0.09, -1.18,  1.55,  0.54],\n",
       "         [-0.20,  0.69, -1.34,  1.65,  1.98, -0.10,  0.49, -0.44],\n",
       "         [-0.49, -0.36, -0.06, -0.48,  0.99,  0.27, -1.83,  0.36]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # shape: (batch_size x context_length x vocab_size) == (B x T x C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7806c8",
   "metadata": {},
   "source": [
    "It has 3 dimensions: batch, time/context, features.  Let's try to treat this matrix so that every value is the mean of all prior values _in the same batch item_.  So for example, the 3rd token (index 2) on the 2nd item in our batch (index 1) has features: <br/>\n",
    "`[-0.1,  0.8,  0.6,  1.9,  1.0, -0.9,  0.8, -0.3]`\n",
    "\n",
    "We want these features to be the averages of the features of itself and all the features of the prior tokens: \n",
    "\n",
    "- `[-0.4,  1.5,  0.2,  1.1,  0.0, -0.1,  0.6,  0.6]`\n",
    "- `[ 0.5,  0.2, -0.9,  1.5, -0.9, -0.5, -0.8,  0.5]`\n",
    "\n",
    "Let's start by applying a triangular vector (shape ) to each batch item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6df954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1.]]),\n",
       " torch.Size([6, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "tril, tril.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894edf4",
   "metadata": {},
   "source": [
    "Let's apply this to our entire training data set; using broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbc80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9,  1.5,  0.9, -2.1,  0.7, -1.2, -0.0, -1.6],\n",
       "         [ 1.2,  3.1,  0.5, -3.5, -0.0, -1.8, -0.8, -0.8],\n",
       "         [ 2.8,  3.0,  0.0, -3.1, -0.8, -0.7, -0.0,  0.8],\n",
       "         [ 4.1,  4.3,  0.6, -1.7, -1.0, -0.7, -0.3,  1.7],\n",
       "         [ 2.7,  3.4,  0.4, -0.0, -0.7, -1.1,  0.0,  0.9],\n",
       "         [ 1.2,  4.4, -0.5, -0.6, -2.0,  1.0, -1.2,  0.4]],\n",
       "\n",
       "        [[-0.9, -0.7,  0.1,  0.5, -0.5,  1.2, -0.8, -0.7],\n",
       "         [-2.3, -0.6,  0.0,  1.2, -0.6,  3.0, -2.0,  0.6],\n",
       "         [-0.9,  0.2,  2.2,  1.7, -0.2,  2.8, -3.1,  1.9],\n",
       "         [-1.0,  0.8,  2.3,  2.2,  0.3,  2.2, -5.3,  1.2],\n",
       "         [-1.0,  0.4,  0.9,  1.6,  0.9,  2.7, -4.1,  1.2],\n",
       "         [-0.3, -0.1, -0.1,  2.2, -0.9,  1.9, -2.8,  1.7]],\n",
       "\n",
       "        [[-2.5,  0.5,  0.8,  0.0,  0.6,  0.6,  1.1, -0.5],\n",
       "         [-2.7,  1.2,  1.2,  0.2,  0.9,  1.9,  1.1, -0.8],\n",
       "         [-4.2,  1.1,  0.6,  0.7,  1.6,  1.9,  0.7, -0.2],\n",
       "         [-4.2,  1.4,  0.7,  1.4,  2.7,  2.3,  1.4,  0.2],\n",
       "         [-2.2,  2.4, -0.7,  0.3,  2.6,  3.9,  2.1,  0.8],\n",
       "         [-1.1,  2.4, -2.5,  1.2,  2.2,  5.0,  1.4,  1.4]],\n",
       "\n",
       "        [[-1.0,  1.0,  1.6,  1.5,  0.3, -0.2, -0.7,  0.1],\n",
       "         [-0.6,  1.9,  1.2,  3.1, -2.2, -0.6, -1.9,  0.9],\n",
       "         [-2.5,  2.2,  1.2,  2.7, -1.9, -1.4, -1.8, -0.2],\n",
       "         [-4.1,  3.5,  2.5,  2.8, -3.5, -0.6, -1.0,  1.8],\n",
       "         [-4.1,  3.6,  1.7,  2.6, -4.4, -2.2, -2.1,  1.3],\n",
       "         [-4.6,  2.1, -0.3,  2.7, -3.4, -2.7, -1.4,  2.0]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril @ x # element-wise (T,T) @ (BxTxC) == (BxTxT) @ (BxTxC) == (BxTxC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c870b",
   "metadata": {},
   "source": [
    "This is similar to our previous example on how to incrementally add numbers, but now with an additional broadcasted batch dimension.  We'll want not to add those numbers those, but to average them out as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f6988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "        [0.5, 0.5, 0.0, 0.0, 0.0, 0.0],\n",
       "        [0.3, 0.3, 0.3, 0.0, 0.0, 0.0],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.0, 0.0],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.0],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tril / torch.sum(tril, 1, keepdim=True) # keepdim for broadcasting\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e72228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9,  1.5,  0.9, -2.1,  0.7, -1.2, -0.0, -1.6],\n",
       "         [-0.8,  1.6, -0.4, -1.4, -0.7, -0.6, -0.8,  0.8],\n",
       "         [ 1.6, -0.2, -0.5,  0.4, -0.8,  1.1,  0.8,  1.7],\n",
       "         [ 1.3,  1.3,  0.6,  1.3, -0.2,  0.0, -0.3,  0.9],\n",
       "         [-1.4, -0.9, -0.2,  1.7,  0.3, -0.4,  0.3, -0.8],\n",
       "         [-1.6,  1.0, -0.9, -0.6, -1.3,  2.1, -1.2, -0.5]]),\n",
       " tensor([[ 1.9,  1.5,  0.9, -2.1,  0.7, -1.2, -0.0, -1.6],\n",
       "         [ 0.6,  1.6,  0.3, -1.8, -0.0, -0.9, -0.4, -0.4],\n",
       "         [ 0.9,  1.0,  0.0, -1.0, -0.3, -0.2, -0.0,  0.3],\n",
       "         [ 1.0,  1.1,  0.2, -0.4, -0.3, -0.2, -0.1,  0.4],\n",
       "         [ 0.5,  0.7,  0.1, -0.0, -0.1, -0.2,  0.0,  0.2],\n",
       "         [ 0.2,  0.7, -0.1, -0.1, -0.3,  0.2, -0.2,  0.1]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bag_of_words_with_matrix = weights @ x\n",
    "x[0], x_bag_of_words_with_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e9765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bag_of_words.allclose(x_bag_of_words_with_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b460af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.93,  1.49,  0.90, -2.11,  0.68, -1.23, -0.04, -1.60],\n",
      "        [-0.75,  1.65, -0.39, -1.40, -0.73, -0.56, -0.77,  0.76],\n",
      "        [ 1.64, -0.16, -0.50,  0.44, -0.76,  1.08,  0.80,  1.68],\n",
      "        [ 1.28,  1.30,  0.61,  1.33, -0.23,  0.04, -0.25,  0.86],\n",
      "        [-1.38, -0.87, -0.22,  1.72,  0.32, -0.42,  0.31, -0.77],\n",
      "        [-1.56,  1.00, -0.88, -0.60, -1.27,  2.12, -1.23, -0.49]])\n",
      "===\n",
      "tensor([[ 1.93,  1.49,  0.90, -2.11,  0.68, -1.23, -0.04, -1.60],\n",
      "        [ 0.59,  1.57,  0.25, -1.75, -0.02, -0.90, -0.41, -0.42],\n",
      "        [ 0.94,  0.99,  0.00, -1.02, -0.27, -0.24, -0.00,  0.28],\n",
      "        [ 1.02,  1.07,  0.16, -0.43, -0.26, -0.17, -0.07,  0.42],\n",
      "        [ 0.54,  0.68,  0.08, -0.00, -0.14, -0.22,  0.01,  0.18],\n",
      "        [ 0.19,  0.73, -0.08, -0.10, -0.33,  0.17, -0.20,  0.07]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2, sci_mode=False, profile='short')\n",
    "print(x[0])\n",
    "print('===')\n",
    "print(x_bag_of_words_with_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241686c9",
   "metadata": {},
   "source": [
    "## Doing the same with SoftMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6146886",
   "metadata": {},
   "source": [
    "This was our tril matrix, which we got by `tril = torch.tril(torch.ones(T,T))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc9393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95c7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.zeros(T,T)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023efdd",
   "metadata": {},
   "source": [
    "We can mask the weights and and apply a number (here minus infinity) to the non-masked values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed61e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights.masked_fill(tril == 0, float('-inf')) # => this is essentially saying: the future cannot communicate with the past\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361f220",
   "metadata": {},
   "source": [
    "The above matrix is essentially making sure that for:\n",
    "\n",
    "- the first token (which is line 1), it only has itself to refer to:   `[0., -inf, -inf, -inf, -inf, -inf]`\n",
    "- token 2 (which is line 2), has itself and token 1 to refer to:       `[0., 0., -inf, -inf, -inf, -inf]`\n",
    "- token 3 (which is line 3), has token 1, 2 and itself to refer to:    `[0., 0., 0., -inf, -inf, -inf]`\n",
    "\n",
    "and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.50, 0.50, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.33, 0.33, 0.33, 0.00, 0.00, 0.00],\n",
       "        [0.25, 0.25, 0.25, 0.25, 0.00, 0.00],\n",
       "        [0.20, 0.20, 0.20, 0.20, 0.20, 0.00],\n",
       "        [0.17, 0.17, 0.17, 0.17, 0.17, 0.17]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights.softmax(1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87d111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bag_of_words_using_softmax = weights @ x\n",
    "torch.allclose(x_bag_of_words_using_softmax, x_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77743c99",
   "metadata": {},
   "source": [
    "(For more explanation, see [Let's build GPT: from scratch, in code, spelled out.](https://youtu.be/kCc8FmEb1nY?t=3355))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43667e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "What we've done here is to do a weighted average of elements and their past using matrix multiplication.  In our case here, all weights were equal, but you can see that this does not have to be the case necesarily.  The elements in the lower part of the triangular weights matrix determine how much of each element in the past the weighted average is build of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2b26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
