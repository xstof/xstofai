{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341662c6-481d-4f92-8503-1a6bbe143dd3",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7714a-bb40-4ed4-8ee0-bf541a1f1383",
   "metadata": {},
   "source": [
    "The below personal learning notes made use of [Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff7092-c379-4a92-936e-51d21c2d7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(precision=1, sci_mode=False, profile='short')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c85faf-19b7-4fae-be47-8fefd1ce95a4",
   "metadata": {},
   "source": [
    "## What is self-attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127bedb-2259-4371-a142-5a52c55a2ef3",
   "metadata": {},
   "source": [
    "Self-Attention started out from research work in translation and was introduced to give access to all elements in a sequence at each time step.  In language tasks, the meaning of a word can depend on the context within a larger text document.  Attention enables the model to weigh the importance of different elements in the input sequence and adjust their influence on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f5447-e490-481b-9e67-caf7088fb80d",
   "metadata": {},
   "source": [
    "## Embedding an Input Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e6d1d-6a9e-4e59-a02e-1e192545d4be",
   "metadata": {},
   "source": [
    "Our input is: \"Playing music makes me very happy\".  We'll create an embeding for this entire sentence first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2806c-2d72-4258-95b6-548e20114c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Playing', 'music', 'makes', 'me', 'very', 'happy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Playing music makes me very happy\"\n",
    "\n",
    "sentence_words = sentence.split()\n",
    "sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5741b7-579a-4af4-9aad-84bae49fab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Playing', 'happy', 'makes', 'me', 'music', 'very']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_words_sorted = sorted(sentence_words)\n",
    "sentence_words_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302470f-6f89-43ec-a8e1-09515d85c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Playing': 0, 'happy': 1, 'makes': 2, 'me': 3, 'music': 4, 'very': 5}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {word_str:word_idx for word_idx, word_str in enumerate(sentence_words_sorted)}\n",
    "dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affec714-84fc-4520-ab58-5abf2601280f",
   "metadata": {},
   "source": [
    "`dict` is our dictionary, conveniently restricted to just the words we're using here.  Every word we're using has a number associated (the index in our dictionary.  \n",
    "\n",
    "We can now translate our sentence in an array of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855eb7d-de37-4383-abee-8e448980a4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 2, 3, 5, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_int = torch.tensor([dict[word] for word in sentence_words])\n",
    "sentence_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e66a8-73c3-4651-ad67-82ec844cfb13",
   "metadata": {},
   "source": [
    "Now that our sentence is translated into a list of integers, we can use those with an embedding layer to encode the inputs into a real vector embedding.  Let's use 16 dimensions, so that each word is translated/mapped onto an embedding of 16 floats.\n",
    "\n",
    "If our sentence is 6 words (or whatever is the context length we end up choosing), the resulting vector after our embedding layer will be: $6 \\times 16$.  We'll create a pytorch embedding layer with 6 possible indices and a 16-dimensional embedding vector for each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581c473-51db-4ece-994f-b500a6da5939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3, -0.2, -0.3, -0.6,  0.3,  0.7, -0.2, -0.4,  0.8, -1.2,  0.7, -1.4,\n",
      "          0.2,  1.9,  0.5,  0.3],\n",
      "        [ 0.5,  1.0, -0.3, -1.1, -0.0,  1.6, -2.3,  1.1,  0.7,  0.7, -0.9, -0.1,\n",
      "         -0.2,  0.1,  0.4, -1.4],\n",
      "        [-1.3,  0.2, -2.1,  1.1, -0.4, -0.9, -0.5, -1.1,  0.9,  1.6,  0.6, -0.2,\n",
      "          0.1, -0.1,  0.3, -0.6],\n",
      "        [ 0.9,  1.6, -1.5,  1.1, -1.2,  1.3,  1.1,  0.1,  2.2, -0.8, -0.3,  0.8,\n",
      "         -0.7, -0.8,  0.2,  0.2],\n",
      "        [ 0.3, -0.5,  1.0,  0.8, -0.4,  0.5, -0.2, -1.7, -1.6, -1.1,  0.9, -0.7,\n",
      "         -0.6, -0.7,  0.6, -1.4],\n",
      "        [-0.1, -1.0, -0.2,  0.9,  1.6,  1.3,  1.3, -0.2,  0.5, -1.6,  1.0, -1.1,\n",
      "         -1.2,  0.3, -0.6, -2.8]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "embed = torch.nn.Embedding(6,16)\n",
    "sentence_embedded = embed(sentence_int).detach()\n",
    "print(sentence_embedded)\n",
    "print(sentence_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b207e-5de7-40c1-8533-3debd497a9d5",
   "metadata": {},
   "source": [
    "So, we gave the embedding a tensor of 6 integers, which got translated in $6 \\times 16$ tensors, meaning: each index, representing a word, it translated into an array of 16 floats.  We can look into the weights of our embedding layer here as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8b2e8-581f-4247-a125-ee071afde14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3, -0.2, -0.3, -0.6,  0.3,  0.7, -0.2, -0.4,  0.8, -1.2,  0.7, -1.4,\n",
       "          0.2,  1.9,  0.5,  0.3],\n",
       "        [-0.1, -1.0, -0.2,  0.9,  1.6,  1.3,  1.3, -0.2,  0.5, -1.6,  1.0, -1.1,\n",
       "         -1.2,  0.3, -0.6, -2.8],\n",
       "        [-1.3,  0.2, -2.1,  1.1, -0.4, -0.9, -0.5, -1.1,  0.9,  1.6,  0.6, -0.2,\n",
       "          0.1, -0.1,  0.3, -0.6],\n",
       "        [ 0.9,  1.6, -1.5,  1.1, -1.2,  1.3,  1.1,  0.1,  2.2, -0.8, -0.3,  0.8,\n",
       "         -0.7, -0.8,  0.2,  0.2],\n",
       "        [ 0.5,  1.0, -0.3, -1.1, -0.0,  1.6, -2.3,  1.1,  0.7,  0.7, -0.9, -0.1,\n",
       "         -0.2,  0.1,  0.4, -1.4],\n",
       "        [ 0.3, -0.5,  1.0,  0.8, -0.4,  0.5, -0.2, -1.7, -1.6, -1.1,  0.9, -0.7,\n",
       "         -0.6, -0.7,  0.6, -1.4]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a8c21-0d80-4665-9226-7f0390f09717",
   "metadata": {},
   "source": [
    "This is basically a kind of \"lookup\" matrix, where we can lookup the embedding vector corresponding to every token in our dictionary.  As such: dictionary token with index:\n",
    "\n",
    "- `0` will return: `[0.3, -0.2, -0.3, -0.6,  0.3,  0.7, -0.2, -0.4,  0.8, -1.2,  0.7, -1.4, 0.2,  1.9,  0.5,  0.3]`\n",
    "- `1` will return: `[-0.1, -1.0, -0.2,  0.9,  1.6,  1.3,  1.3, -0.2,  0.5, -1.6,  1.0, -1.1, -1.2,  0.3, -0.6, -2.8]`\n",
    "- `2` will return: `[-1.3,  0.2, -2.1,  1.1, -0.4, -0.9, -0.5, -1.1,  0.9,  1.6,  0.6, -0.2, 0.1, -0.1,  0.3, -0.6]`\n",
    "\n",
    "and so on.  Given our sentence had tokens with indexes: $\\begin{bmatrix}\n",
    "0 & 4 & 2 & 3 & 5 & 1\n",
    "\\end{bmatrix}$ we expect first the first row, then the 5th, then 3rd, ... and so on, which gives the same end result:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "0.3 & -0.2 & -0.3 & -0.6 & 0.3 & 0.7 & -0.2 & -0.4 & 0.8 & -1.2 & 0.7 & -1.4 & 0.2 & 1.9 & 0.5 & 0.3 \\\\\n",
    "0.5 & 1.0 & -0.3 & -1.1 & -0.0 & 1.6 & -2.3 & 1.1 & 0.7 & 0.7 & -0.9 & -0.1 & -0.2 & 0.1 & 0.4 & -1.4 \\\\\n",
    "-1.3 & 0.2 & -2.1 & 1.1 & -0.4 & -0.9 & -0.5 & -1.1 & 0.9 & 1.6 & 0.6 & -0.2 & 0.1 & -0.1 & 0.3 & -0.6 \\\\\n",
    "0.9 & 1.6 & -1.5 & 1.1 & -1.2 & 1.3 & 1.1 & 0.1 & 2.2 & -0.8 & -0.3 & 0.8 & -0.7 & -0.8 & 0.2 & 0.2 \\\\\n",
    "0.3 & -0.5 & 1.0 & 0.8 & -0.4 & 0.5 & -0.2 & -1.7 & -1.6 & -1.1 & 0.9 & -0.7 & -0.6 & -0.7 & 0.6 & -1.4 \\\\\n",
    "-0.1 & -1.0 & -0.2 & 0.9 & 1.6 & 1.3 & 1.3 & -0.2 & 0.5 & -1.6 & 1.0 & -1.1 & -1.2 & 0.3 & -0.6 & -2.8\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f691eb-c88b-4ec0-869c-1f8d5aa0089a",
   "metadata": {},
   "source": [
    "## Defining weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a395595-05f3-4c9b-88b3-d77ab9a826dd",
   "metadata": {},
   "source": [
    "### Set up and dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc8583-3fd6-4810-bad2-928c316c24f0",
   "metadata": {},
   "source": [
    "Self-attention has 3 weight matrices which are each adjusted, like other model parameters, during training.\n",
    "\n",
    "- $W_{q}$: projects our input to the *query*\n",
    "- $W_{k}$: projects our input to the *key*\n",
    "- $W_{v}$: projects our input to the *value*\n",
    "\n",
    "each of *query* $q$, *key* $k$ and *value* $v$ are vectors of an input element.  We can calculate those through matrix multiplication between those $W$ matrices and the embedded inputs $x$.  Our sequence has length $T$.\n",
    "\n",
    "- $q^{i} = W_{q} x^{(i)}$ for the element on index i, i between $0$ and $T-1$\n",
    "- $k^{i} = W_{k} x^{(i)}$ for the element on index i, i between $0$ and $T-1$\n",
    "- $v^{i} = W_{v} x^{(i)}$ for the element on index i, i between $0$ and $T-1$\n",
    "\n",
    "This will give us three vectors for each input element (token) in our sequence.\n",
    "\n",
    "Let's assume that $d$ is the size (number of dimensions) of each (embedded) word vector x (here 16).  Our vector $q^{i}$ is the query vector for word at index $i$ and has a dimension we can choose.  We'll call this $d_q$.  In the same way we'll call $d_k$ as the dimension for $k^{i}$.\n",
    "\n",
    "We'll calculate the dot product between the query and key vectors, this means that each of them needs to have the same dimensions: $d_q = d_k$. Let's choose $d_q = d_k = 24$ in this case.<br/>\n",
    "If $$q^{i} = W_{q} x^{(i)}$$ then: \n",
    "\n",
    "- the dimension for $q^{i}$ is $d_q$ which is the same as $d_k$, here 24, something we chose\n",
    "- the dimension for $W_{q}$ is $d_q \\times d$, here 24 by 16, because every word is represented by 16 floats\n",
    "- the dimension for $x^{(i)}$ is $d$, here 16 (16 floats for every word)\n",
    "\n",
    "Our dimension for the value vector can be chosen arbitrarily, let's say: 28 in our example.  That's the size of the resulting context vector.\n",
    "\n",
    "Let's set up some arbitrary weight matrices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f117e-db24-444d-9ac2-4fc6ad7c2768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 16\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "W_query = torch.rand(d_q,d)\n",
    "W_key = torch.rand(d_k,d)\n",
    "W_value = torch.rand(d_v,d)\n",
    "\n",
    "W_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26300ba9-f879-493a-8622-571b3c8d77d9",
   "metadata": {},
   "source": [
    "### Calculate the query, key and value for one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400f031-7747-4b26-97e2-eb3147c65cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query has shape torch.Size([24, 16]), x_2 has shape torch.Size([16]) and resulting query_2 has shape: torch.Size([24])\n",
      "\n",
      "the resulting tensor is our query tensor for word at index 2:\n",
      "tensor([-2.4, -1.3,  0.0,  0.4, -0.2, -1.8, -1.0, -0.7, -1.9, -0.0, -1.6, -0.7,\n",
      "        -2.0, -1.3, -1.6, -1.5, -1.1, -2.8, -0.4,  0.7, -1.7,  1.0, -1.1, -3.2])\n"
     ]
    }
   ],
   "source": [
    "x_2 = sentence_embedded[2]\n",
    "query_2 = W_query.matmul(x_2)\n",
    "print(f'W_query has shape {W_query.shape}, x_2 has shape {x_2.shape} and resulting query_2 has shape: {query_2.shape}\\n')\n",
    "print('the resulting tensor is our query tensor for word at index 2:')\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539fd2a-bda3-4b5d-b8a5-c1f6c4c2a79c",
   "metadata": {},
   "source": [
    "we can do the same to get the key and value vector for the word at index 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bae81d-81d1-47d5-818c-5b4d9230d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4, -1.3,  0.0,  0.4, -0.2, -1.8, -1.0, -0.7, -1.9, -0.0, -1.6, -0.7,\n",
      "        -2.0, -1.3, -1.6, -1.5, -1.1, -2.8, -0.4,  0.7, -1.7,  1.0, -1.1, -3.2])\n",
      "tensor([ 0.6, -2.3, -1.8, -1.3, -1.9, -0.6, -1.5, -3.0,  0.4, -1.9, -0.7, -2.1,\n",
      "        -2.0, -0.9, -1.6, -2.1, -0.4, -0.2,  0.5, -1.1, -2.5, -0.4,  0.4, -3.0])\n",
      "tensor([-1.1, -0.9, -3.0, -0.7, -2.2,  0.1,  0.0, -2.8, -2.1,  0.7, -0.7, -1.6,\n",
      "        -2.6, -1.3, -0.9, -0.5, -1.8, -3.0, -0.7, -1.3,  0.5, -1.1, -1.8, -2.2,\n",
      "         0.6, -0.0, -1.8, -1.3])\n"
     ]
    }
   ],
   "source": [
    "query_2 = W_query @ x_2 # same as matmul\n",
    "key_2 = W_key @ x_2\n",
    "value_2 = W_value @ x_2\n",
    "\n",
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48b658-aa81-4517-9fd1-64975bf54cd9",
   "metadata": {},
   "source": [
    "### Generalizing the calculation to all inputs in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134aac3-c752-4ce5-ab11-0ec5bc7cf83d",
   "metadata": {},
   "source": [
    "We can generalize what we did for a single token or word to all of our inputs in our sequence now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ebd5e-7e58-44e2-92df-7a846a50f97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: \n",
      "tensor([[ 0.9,  1.2,  2.2,  1.3,  0.8, -1.6, -0.2,  2.0, -0.4,  1.7,  0.1,  2.2,\n",
      "         -0.2, -0.7, -0.2, -0.2,  0.8,  1.0,  0.7,  1.7,  2.8,  1.5, -0.9,  1.1],\n",
      "        [ 0.9,  0.1,  0.7, -1.1,  1.3, -0.2,  1.0, -0.7,  1.5,  0.3, -0.3,  0.3,\n",
      "          1.5, -1.1,  1.4,  0.4, -2.5,  0.4,  0.0, -0.1,  1.2,  1.3,  1.7,  0.5],\n",
      "        [ 0.6, -2.3, -1.8, -1.3, -1.9, -0.6, -1.5, -3.0,  0.4, -1.9, -0.7, -2.1,\n",
      "         -2.0, -0.9, -1.6, -2.1, -0.4, -0.2,  0.5, -1.1, -2.5, -0.4,  0.4, -3.0],\n",
      "        [ 2.5,  2.0,  1.3,  2.5,  2.3,  3.6,  2.9,  1.0,  3.3,  2.8,  3.6,  1.1,\n",
      "          3.1,  2.8,  1.8,  1.9,  0.4,  1.4,  2.4,  1.3,  2.2,  2.2,  2.4,  1.8],\n",
      "        [-3.1, -2.5, -1.1, -3.5, -4.7, -6.2, -0.9, -3.2, -1.4, -3.5, -2.8, -2.3,\n",
      "         -1.3, -3.1, -2.3,  0.4, -2.5, -3.9, -4.2, -1.6, -2.0, -1.7, -1.0, -5.0],\n",
      "        [-1.1, -1.4,  0.9, -2.3, -2.7, -3.2, -1.4, -1.0, -0.8,  1.0, -2.0, -0.7,\n",
      "         -0.7, -2.5, -2.9, -1.0, -1.0, -1.2, -3.1, -0.6,  1.4, -0.7, -0.9, -1.8]])\n",
      "values: \n",
      " tensor([[-0.8,  0.3,  1.7,  1.6,  2.2,  1.1,  1.7,  1.6,  1.8,  1.0,  1.3,  0.3,\n",
      "          0.3,  0.3,  2.4,  2.0, -1.1,  0.7, -0.2,  0.8,  0.5,  1.0,  1.3,  0.2,\n",
      "         -0.3,  0.9,  1.7, -0.3],\n",
      "        [ 0.5,  0.3,  0.2,  0.1, -0.2, -1.3, -0.9, -1.3, -0.4, -0.1,  1.1,  0.4,\n",
      "         -0.7,  0.1, -1.1,  0.3, -0.3,  0.8, -1.1,  3.0, -0.3,  1.6,  2.7,  0.5,\n",
      "         -2.5, -1.5, -0.4,  0.2],\n",
      "        [-1.1, -0.9, -3.0, -0.7, -2.2,  0.1,  0.0, -2.8, -2.1,  0.7, -0.7, -1.6,\n",
      "         -2.6, -1.3, -0.9, -0.5, -1.8, -3.0, -0.7, -1.3,  0.5, -1.1, -1.8, -2.2,\n",
      "          0.6, -0.0, -1.8, -1.3],\n",
      "        [ 2.2,  3.5, -2.0,  3.1,  0.7,  3.2,  2.8,  0.8,  2.7,  2.6,  0.1,  1.0,\n",
      "          1.1,  3.6,  3.5,  2.5,  2.8,  2.3,  2.6,  4.4,  3.1,  5.2,  2.9,  2.7,\n",
      "          4.3,  1.3,  1.4,  3.8],\n",
      "        [-1.4, -3.1, -1.4, -1.0, -0.9, -2.5, -2.1, -1.9, -2.0, -3.8, -3.9, -3.1,\n",
      "         -2.2, -3.1, -3.7, -1.9, -1.9, -1.7, -1.4, -4.2, -3.5, -1.8, -3.1, -1.7,\n",
      "         -2.1, -1.9, -2.1, -3.5],\n",
      "        [-0.3, -2.7,  0.8,  1.5,  0.0, -1.9, -0.7,  1.2, -1.0, -4.3,  0.8, -3.7,\n",
      "         -1.2, -2.9,  0.7, -1.6, -1.8, -0.4, -1.7, -1.0,  0.2,  2.9, -1.4,  0.9,\n",
      "         -1.4, -2.6, -0.4, -0.7]])\n"
     ]
    }
   ],
   "source": [
    "keys = (W_key @ sentence_embedded.T).T\n",
    "values = (W_value @ sentence_embedded.T).T\n",
    "\n",
    "print(f'keys: \\n{keys}')\n",
    "print(f'values: \\n {values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e37dc8-0147-4295-9e3e-5c74dc6d4976",
   "metadata": {},
   "source": [
    "This is a matrix with one row per word in our input sequence, each such row representing the key or value vector for the correponding word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d0ac2-f490-49e6-8758-d4ed706d531f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fc7323b-9c81-4daf-b6fc-1183ce2d751a",
   "metadata": {},
   "source": [
    "If we want to get to the attention-vector for the second input element, that element will act as the query.  We will matrix-multiply that query with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f99ed-2cdd-4d1e-8896-c577fa7f0516",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4441d-ae46-456c-bd66-463299f85559",
   "metadata": {},
   "source": [
    "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "- [Thinking Like Transformers](https://arxiv.org/abs/2106.06981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119134fe-eea8-4d9d-a0f1-f875272541ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
